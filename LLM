!pip install langchain transformers torch


# Step 1: Install the required libraries
!pip install langchain transformers torch

# Step 2: Import necessary modules
from transformers import pipeline

# Step 3: Load a pre-trained model (e.g., GPT-2)
model_name = "gpt2"  # You can choose any available model
generator = pipeline('text-generation', model=model_name)

# Step 4: Generate text using the model
prompt = "What are the benefits of using LangChain for LLM output parsing?"
output = generator(prompt, max_length=100, num_return_sequences=1)

# Step 5: Print the output
print("Generated Output:")
print(output[0]['generated_text'])

# Example of parsing the output (this is a basic example)
parsed_output = output[0]['generated_text'].split('. ')
print("\nParsed Output:")
for sentence in parsed_output:
    print(f"- {sentence.strip()}")
